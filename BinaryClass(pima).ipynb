{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BinaryClass(pima).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Implementing deep neural network for performing binary classification"
      ],
      "metadata": {
        "id": "Tmwcr1RleUlB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ydqPY5KIcnK3"
      },
      "outputs": [],
      "source": [
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=loadtxt('/content/pima-indians-diabetes.data.csv',delimiter=',')"
      ],
      "metadata": {
        "id": "-_U4eAUweqRv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FI9eEMliiv6t",
        "outputId": "e0790f4b-ace0-49ba-e476-7fd1e7a4ff6e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=dataset[:,0:8]\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26_MwYU5iyO-",
        "outputId": "335ac05c-6f0a-4f42-c9d0-f35286ac564c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sarjQiDi3Sb",
        "outputId": "67d75321-7686-4b12-8723-cc160a8b6a04"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y=dataset[:,8]\n",
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXaRAQRji7cY",
        "outputId": "b57d51a8-e1b7-4f4a-8b01-641a6b8d0fde"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
              "       1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
              "       1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
              "       1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
              "       1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
              "       1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
              "       1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
              "       1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
              "       1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
              "       1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
              "       0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 1., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(12,input_dim=8,activation='relu'))\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "waKTJopyjAFO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_D1_2WXje2y",
        "outputId": "bfb22a6e-5939-460f-a1c4-a6febca9bead"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12)                108       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                130       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 249\n",
            "Trainable params: 249\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics='accuracy')"
      ],
      "metadata": {
        "id": "Q1lV5cHjjhyp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "Xtrain,Xtest,Ytrain,Ytest=train_test_split(X,Y,test_size=0.25,random_state=1)"
      ],
      "metadata": {
        "id": "kK6mC1hIj8Ex"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgr6Y67kkVzG",
        "outputId": "edb2c4e8-908f-4b58-f445-3cb483d9d475"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(576, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xtest.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YD6y82DkYK6",
        "outputId": "0c096a15-2fb1-4e02-d3b5-734c6856487b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(192, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ytrain.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "034sscErkZ0A",
        "outputId": "22197f68-094a-408c-9aca-5d51aa79df3f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(576,)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ytest.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkV-q4oAkeVJ",
        "outputId": "6390f262-7013-4c5e-8377-bf109ebd6734"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(192,)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(Xtrain,Ytrain,epochs=150,batch_size=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xCfbw9Rkf1Z",
        "outputId": "091b00c8-eef3-47c1-f39c-6b15cb03516d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "58/58 [==============================] - 1s 2ms/step - loss: 7.2060 - accuracy: 0.5122\n",
            "Epoch 2/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 1.2938 - accuracy: 0.5434\n",
            "Epoch 3/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.9216 - accuracy: 0.5712\n",
            "Epoch 4/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.8101 - accuracy: 0.5903\n",
            "Epoch 5/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7840 - accuracy: 0.6181\n",
            "Epoch 6/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7410 - accuracy: 0.6285\n",
            "Epoch 7/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.7144 - accuracy: 0.6406\n",
            "Epoch 8/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.6545\n",
            "Epoch 9/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.6354\n",
            "Epoch 10/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.6684\n",
            "Epoch 11/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6658 - accuracy: 0.6458\n",
            "Epoch 12/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.6528\n",
            "Epoch 13/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6626 - accuracy: 0.6510\n",
            "Epoch 14/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6581 - accuracy: 0.6649\n",
            "Epoch 15/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6388 - accuracy: 0.6615\n",
            "Epoch 16/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6432 - accuracy: 0.6632\n",
            "Epoch 17/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.6615\n",
            "Epoch 18/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6365 - accuracy: 0.6736\n",
            "Epoch 19/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6241 - accuracy: 0.6753\n",
            "Epoch 20/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.6649\n",
            "Epoch 21/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6181 - accuracy: 0.6667\n",
            "Epoch 22/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6137 - accuracy: 0.6719\n",
            "Epoch 23/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.6684\n",
            "Epoch 24/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6480 - accuracy: 0.6719\n",
            "Epoch 25/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6105 - accuracy: 0.6944\n",
            "Epoch 26/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6480 - accuracy: 0.6806\n",
            "Epoch 27/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6053 - accuracy: 0.6840\n",
            "Epoch 28/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.6736\n",
            "Epoch 29/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6077 - accuracy: 0.6962\n",
            "Epoch 30/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6068 - accuracy: 0.6788\n",
            "Epoch 31/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5947 - accuracy: 0.6875\n",
            "Epoch 32/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6085 - accuracy: 0.6997\n",
            "Epoch 33/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5947 - accuracy: 0.6806\n",
            "Epoch 34/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6005 - accuracy: 0.6701\n",
            "Epoch 35/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5865 - accuracy: 0.7083\n",
            "Epoch 36/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5898 - accuracy: 0.6927\n",
            "Epoch 37/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.6892\n",
            "Epoch 38/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.6997\n",
            "Epoch 39/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.6944\n",
            "Epoch 40/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.6875\n",
            "Epoch 41/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.6858\n",
            "Epoch 42/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.7031\n",
            "Epoch 43/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.7049\n",
            "Epoch 44/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5771 - accuracy: 0.6927\n",
            "Epoch 45/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5748 - accuracy: 0.7101\n",
            "Epoch 46/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7135\n",
            "Epoch 47/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6031 - accuracy: 0.6910\n",
            "Epoch 48/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5938 - accuracy: 0.7170\n",
            "Epoch 49/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.6927\n",
            "Epoch 50/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.6840\n",
            "Epoch 51/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.7066\n",
            "Epoch 52/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.6892\n",
            "Epoch 53/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5763 - accuracy: 0.7049\n",
            "Epoch 54/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.7153\n",
            "Epoch 55/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.6018 - accuracy: 0.7049\n",
            "Epoch 56/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.6997\n",
            "Epoch 57/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.6962\n",
            "Epoch 58/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7014\n",
            "Epoch 59/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.7153\n",
            "Epoch 60/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.7049\n",
            "Epoch 61/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7240\n",
            "Epoch 62/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7049\n",
            "Epoch 63/150\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.5633 - accuracy: 0.6997\n",
            "Epoch 64/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5605 - accuracy: 0.7066\n",
            "Epoch 65/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5859 - accuracy: 0.7188\n",
            "Epoch 66/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.7118\n",
            "Epoch 67/150\n",
            "58/58 [==============================] - 0s 4ms/step - loss: 0.5544 - accuracy: 0.7014\n",
            "Epoch 68/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.6962\n",
            "Epoch 69/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7274\n",
            "Epoch 70/150\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.5412 - accuracy: 0.7101\n",
            "Epoch 71/150\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.5649 - accuracy: 0.7049\n",
            "Epoch 72/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.7222\n",
            "Epoch 73/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7170\n",
            "Epoch 74/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.7083\n",
            "Epoch 75/150\n",
            "58/58 [==============================] - 0s 4ms/step - loss: 0.5576 - accuracy: 0.7135\n",
            "Epoch 76/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7222\n",
            "Epoch 77/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7170\n",
            "Epoch 78/150\n",
            "58/58 [==============================] - 0s 4ms/step - loss: 0.5552 - accuracy: 0.7153\n",
            "Epoch 79/150\n",
            "58/58 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7222\n",
            "Epoch 80/150\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.5402 - accuracy: 0.7240\n",
            "Epoch 81/150\n",
            "58/58 [==============================] - 0s 4ms/step - loss: 0.5641 - accuracy: 0.7205\n",
            "Epoch 82/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5572 - accuracy: 0.7066\n",
            "Epoch 83/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.7205\n",
            "Epoch 84/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5500 - accuracy: 0.7205\n",
            "Epoch 85/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7170\n",
            "Epoch 86/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7135\n",
            "Epoch 87/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7118\n",
            "Epoch 88/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7135\n",
            "Epoch 89/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7257\n",
            "Epoch 90/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7309\n",
            "Epoch 91/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7240\n",
            "Epoch 92/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7170\n",
            "Epoch 93/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7205\n",
            "Epoch 94/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7361\n",
            "Epoch 95/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7240\n",
            "Epoch 96/150\n",
            "58/58 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.7240\n",
            "Epoch 97/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7344\n",
            "Epoch 98/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7205\n",
            "Epoch 99/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7118\n",
            "Epoch 100/150\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.5343 - accuracy: 0.7344\n",
            "Epoch 101/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7118\n",
            "Epoch 102/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7222\n",
            "Epoch 103/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5417 - accuracy: 0.7257\n",
            "Epoch 104/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7240\n",
            "Epoch 105/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7292\n",
            "Epoch 106/150\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.5269 - accuracy: 0.7188\n",
            "Epoch 107/150\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.5405 - accuracy: 0.7396\n",
            "Epoch 108/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7222\n",
            "Epoch 109/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7153\n",
            "Epoch 110/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7500\n",
            "Epoch 111/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7205\n",
            "Epoch 112/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7292\n",
            "Epoch 113/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7309\n",
            "Epoch 114/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5394 - accuracy: 0.7240\n",
            "Epoch 115/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.7049\n",
            "Epoch 116/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7309\n",
            "Epoch 117/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.7135\n",
            "Epoch 118/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7222\n",
            "Epoch 119/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7309\n",
            "Epoch 120/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.7309\n",
            "Epoch 121/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7240\n",
            "Epoch 122/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5378 - accuracy: 0.7240\n",
            "Epoch 123/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7188\n",
            "Epoch 124/150\n",
            "58/58 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7292\n",
            "Epoch 125/150\n",
            "58/58 [==============================] - 0s 4ms/step - loss: 0.5429 - accuracy: 0.7222\n",
            "Epoch 126/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.7274\n",
            "Epoch 127/150\n",
            "58/58 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.7274\n",
            "Epoch 128/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7031\n",
            "Epoch 129/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5402 - accuracy: 0.7344\n",
            "Epoch 130/150\n",
            "58/58 [==============================] - 0s 4ms/step - loss: 0.5209 - accuracy: 0.7309\n",
            "Epoch 131/150\n",
            "58/58 [==============================] - 0s 4ms/step - loss: 0.5448 - accuracy: 0.7431\n",
            "Epoch 132/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5243 - accuracy: 0.7500\n",
            "Epoch 133/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.7378\n",
            "Epoch 134/150\n",
            "58/58 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7205\n",
            "Epoch 135/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5462 - accuracy: 0.7153\n",
            "Epoch 136/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.7448\n",
            "Epoch 137/150\n",
            "58/58 [==============================] - 0s 4ms/step - loss: 0.5313 - accuracy: 0.7361\n",
            "Epoch 138/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5299 - accuracy: 0.7378\n",
            "Epoch 139/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7240\n",
            "Epoch 140/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7344\n",
            "Epoch 141/150\n",
            "58/58 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.7465\n",
            "Epoch 142/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7361\n",
            "Epoch 143/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7257\n",
            "Epoch 144/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5247 - accuracy: 0.7326\n",
            "Epoch 145/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7378\n",
            "Epoch 146/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7431\n",
            "Epoch 147/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.7344\n",
            "Epoch 148/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7569\n",
            "Epoch 149/150\n",
            "58/58 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7326\n",
            "Epoch 150/150\n",
            "58/58 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7535\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f53b861c210>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions=model.predict(Xtest)"
      ],
      "metadata": {
        "id": "PzQtM8U4kbmZ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (15):\n",
        "  print(Xtest[i].tolist(),predictions[i],Ytest[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UScf2qK0lkqW",
        "outputId": "36366584-95d2-4b22-9e69-365120f33688"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7.0, 136.0, 74.0, 26.0, 135.0, 26.0, 0.647, 51.0] [0.6268313] 0.0\n",
            "[1.0, 151.0, 60.0, 0.0, 0.0, 26.1, 0.179, 22.0] [0.6415241] 0.0\n",
            "[6.0, 109.0, 60.0, 27.0, 0.0, 25.0, 0.206, 27.0] [0.5144493] 0.0\n",
            "[3.0, 61.0, 82.0, 28.0, 0.0, 34.4, 0.243, 46.0] [0.00238094] 0.0\n",
            "[1.0, 116.0, 78.0, 29.0, 180.0, 36.1, 0.496, 25.0] [0.34224063] 0.0\n",
            "[0.0, 119.0, 66.0, 27.0, 0.0, 38.8, 0.259, 22.0] [0.35229513] 0.0\n",
            "[4.0, 122.0, 68.0, 0.0, 0.0, 35.0, 0.394, 29.0] [0.58145404] 0.0\n",
            "[1.0, 119.0, 54.0, 13.0, 50.0, 22.3, 0.205, 24.0] [0.5249626] 0.0\n",
            "[1.0, 97.0, 70.0, 40.0, 0.0, 38.1, 0.218, 30.0] [0.38095683] 0.0\n",
            "[0.0, 105.0, 64.0, 41.0, 142.0, 41.5, 0.173, 22.0] [0.32859433] 0.0\n",
            "[7.0, 137.0, 90.0, 41.0, 0.0, 32.0, 0.391, 39.0] [0.43012047] 0.0\n",
            "[1.0, 95.0, 74.0, 21.0, 73.0, 25.9, 0.673, 36.0] [0.12255996] 0.0\n",
            "[0.0, 180.0, 78.0, 63.0, 14.0, 59.4, 2.42, 25.0] [0.45780644] 1.0\n",
            "[11.0, 138.0, 74.0, 26.0, 144.0, 36.1, 0.557, 50.0] [0.6876156] 1.0\n",
            "[0.0, 118.0, 64.0, 23.0, 89.0, 0.0, 1.731, 21.0] [0.3518062] 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "USUYI4p7lz9D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}